# ğŸ¨ ChromaMatch

**AI-powered color analysis & personalized fashion recommendations using Computer Vision + RAG + MLOps + Cloud.**

ChromaMatch detects **skin tone**, **undertone**, **eye color**, **hair color**, and generates highly personalized recommendations using a **Retrieval-Augmented Generation (RAG)** pipeline.
The project integrates **MLOps**, **LLMOps**, **Prompt Engineering**, **Cloud Deployment**, **Monitoring**, and **Guardrails**.

---

# ğŸš€ Quickstart

```bash
git clone https://github.com/noori-shaukat/ChromaMatch.git
cd ChromaMatch
make install
make dev
```

### Common Make Targets

| Command            | Description                  |
| ------------------ | ---------------------------- |
| `make dev`         | Run FastAPI server           |
| `make test`        | Run tests                    |
| `make docker`      | Build Docker image           |
| `make docker-run`  | Run container                |
| `make build-index` | Build FAISS RAG index        |
| `make rag`         | Full RAG pipeline end-to-end |

---

# ğŸ§± System Architecture

![Architecture Diagram](monitoring/screenshots/archdiagram.png)

---

# ğŸ§ª MLflow Model Registry

* **Experiment:** `ChromaMatch`
* **Model Name:** `ChromaMatch_Model`
* **Version:** v1

![MLFlow](monitoring/screenshots/mlflow.png)

---

# ğŸ§¾ Evidently Data Drift Dashboard

![Data Drift Report](monitoring/screenshots/data_drift_report.png)

---

# ğŸ“ˆ Prometheus Metrics Tracking

![Prometheus Monitoring](monitoring/screenshots/prometheus.png)

---

# ğŸ“‰ Grafana Real-Time Dashboard

![Grafana Dashboard](monitoring/screenshots/grafana.png)

---

# ğŸ§¹ Pre-commit Hooks

Configured to maintain code quality:

* `trailing-whitespace`
* `end-of-file-fixer`
* `detect-secrets`
* `black`
* `ruff`

Run:

```bash
pre-commit run --all-files
```

---

# ğŸ“¡ API Documentation

FastAPI auto-generates live documentation.

### Swagger UI

ğŸ‘‰ [http://13.60.180.47:8000/docs](http://13.60.180.47:8000/docs)

### ReDoc

ğŸ‘‰ [http://13.60.180.47:8000/redoc](http://13.60.180.47:8000/redoc)

---

## `/health`

Check server status.

```json
{"status": "ok"}
```

---

## `/analyze` â€“ (POST)

Upload an image â†’ receive:

* Skin Tone
* Tone Group
* Descriptor
* Undertone
* Eye Color
* Hair Color

Example:

```json
{
  "skin_tone": "MST 4",
  "tone_group": "Medium",
  "descriptor": "Sand / Light Medium",
  "undertone": "Warm",
  "eye_color": ["Brown"],
  "hair_color": "Dark Brown"
}
```

![Swagger UI](monitoring/screenshots/swagger.png)

---

# ğŸ§  D1 â€” Prompt Engineering Workflow

This project includes a full experimental pipeline for **prompt robustness testing**.

### ğŸ“ Directory Structure

```
experiments/
 â”œâ”€â”€ prompts/
 â”‚    â”œâ”€â”€ baseline_zeroshot.txt
 â”‚    â”œâ”€â”€ few_shot.txt
 â”‚    â””â”€â”€ advanced_cot.txt
 â”œâ”€â”€ results/
 â”œâ”€â”€ eval_prompts.py
 â””â”€â”€ qualitative_score.py
 data/
 â””â”€â”€ eval.jsonl
```

### Required Prompt Strategies (Implemented)

| Strategy                 | Description                        |
| ------------------------ | ---------------------------------- |
| **Baseline Zero-shot**   | Minimal prompt â†’ direct generation |
| **Few-shot (k=3 & k=5)** | Example-driven recommendations     |
| **Advanced**             | Chain-of-Thought (CoT) reasoning   |

### Evaluation Includes:

#### âœ” Quantitative Metrics

* **Cosine Similarity (SentenceTransformers)**
* Optional BLEU / ROUGE via `sacrebleu`

#### âœ” Qualitative Metrics (Human-in-the-loop)

Users manually score:

* **Factuality (1â€“5)**
* **Helpfulness (1â€“5)**

#### âœ” MLflow Logging

All experiment runs logged automatically:

ğŸ‘‰ [http://13.60.180.47:5000/](http://13.60.180.47:5000/)

### Final Deliverable

A full **prompt_report.md** summarizing:

* Each prompt strategy
* Strengths & weaknesses
* Quantitative results
* Qualitative scores
* Failure cases
* Best performing prompt

---

# ğŸ” D2 â€” RAG (Retrieval-Augmented Generation) Pipeline

### ğŸ“ Code Structure

```
src/rag/
 â”œâ”€â”€ ingest.py        # Web scraping + document cleaning
 â”œâ”€â”€ vector_store.py  # FAISS index builder + persistence
 â”œâ”€â”€ retriever.py     # Query to vector search
 â”œâ”€â”€ rag_pipeline.py  # Core pipeline
 â””â”€â”€ recommend.py     # Endpoint logic
```

### RAG Flow

1. Scrape color/fashion websites
2. Clean + chunk documents
3. Encode using SentenceTransformers
4. Store vectors in **FAISS**
5. Retrieve top-k matches
6. Feed retrieved chunks + user skin profile â†’ LLM
7. Generate personalized recommendations

### Reproducibility

```bash
make rag
```

### RAG Architecture Diagram

Included in repo.

---

# ğŸ›¡ï¸ D3 â€” Guardrails & Safety Mechanisms

Guardrails applied at **input**, **retrieval**, and **output** stages.

### Implemented Policies

### 1ï¸âƒ£ Input Validation

* PII detection
* Prompt injection filtering
* Image safety validation

### 2ï¸âƒ£ Output Moderation

* Toxicity thresholding
* Hallucination suppression
* Confidence scoring

All guardrail violations logged to:

* **Prometheus**
* **MLflow**

---

# ğŸ“‰ D4 â€” LLM Evaluation & Monitoring

Monitored in real time:

* Latency
* Token usage
* Cost
* Guardrail violations
* Retrieval scores
* System resource usage

### Dashboards

| Service    | URL                                                    |
| ---------- | ------------------------------------------------------ |
| MLflow     | [http://13.60.180.47:5000/](http://13.60.180.47:5000/) |
| Grafana    | [http://13.60.180.47:3000/](http://13.60.180.47:3000/) |
| Prometheus | [http://13.60.180.47:9090/](http://13.60.180.47:9090/) |
| Evidently  | [http://13.60.180.47:7000/](http://13.60.180.47:7000/) |

---

# â˜ï¸ D7 â€” Cloud Integration (Required)

ChromaMatch uses **AWS** cloud services:

| Cloud Service         | Purpose                                                 |
| --------------------- | ------------------------------------------------------- |
| **S3**                | Store FAISS index + documents + MLflow artifacts        |
| **EC2**               | Host FastAPI, RAG pipeline, MLflow, Grafana, Prometheus |
| **Lambda (Optional)** | Periodic evaluation of RAG pipeline                     |

### Deployment Includes

* Full EC2 setup
* S3 integration
* Open ports for monitoring stack
* Configuration screenshots in repo

---

# ğŸ” D8 â€” Security & Compliance

### SECURITY.md covers:

* Prompt injection defenses
* Safe LLM output handling
* Privacy rules
* PII filtering (image & text)

### Dependency Scanning

```bash
pip-audit
```

CI fails if critical CVEs found.

### Responsible AI

* No personal data stored
* All logs anonymized
* Guardrails enforce safe content

---

# ğŸŒ©ï¸ Cloud Deployment (Step-by-Step)

### 1. Launch EC2

```bash
ssh -i chromamatch-key.pem ubuntu@13.60.180.47
```

### 2. Clone repo

```bash
git clone https://github.com/noori-shaukat/ChromaMatch.git
cd ChromaMatch
```

### 3. Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 4. Run MLflow

```bash
mlflow server --host 0.0.0.0 --port 5000 \
 --backend-store-uri sqlite:///mlflow.db \
 --default-artifact-root s3://chromamatch-artifacts/
```

### 5. Start FastAPI

```bash
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

### 6. Start Monitoring Stack

* **Prometheus:** [http://13.60.180.47:9090](http://13.60.180.47:9090)
* **Grafana:** [http://13.60.180.47:3000](http://13.60.180.47:3000)
* **Evidently:** [http://13.60.180.47:7000](http://13.60.180.47:7000)

---

# ğŸ“ Useful Links

| Service      | URL                                                            |
| ------------ | -------------------------------------------------------------- |
| MLflow       | [http://13.60.180.47:5000/](http://13.60.180.47:5000/)         |
| Grafana      | [http://13.60.180.47:3000/](http://13.60.180.47:3000/)         |
| Prometheus   | [http://13.60.180.47:9090/](http://13.60.180.47:9090/)         |
| Evidently    | [http://13.60.180.47:7000/](http://13.60.180.47:7000/)         |
| Backend API  | [http://13.60.180.47:8000/](http://13.60.180.47:8000/)         |
| Swagger Docs | [http://13.60.180.47:8000/docs](http://13.60.180.47:8000/docs) |

---